---
layout: post  
title: mysql大数据表设计分析  
category: 技术分享  
slug: mysql-big-data-design  
Tags: [mysql]
---

如何设计或优化千万级别的大表

首先针对这个课题要给自己提出一些问题：  

> 1. 数据的容量：1-3年内会大概多少条数据，每条数据大概多少字节； 

> 2. 数据项：是否有大字段，那些字段的值是否经常被更新；   

> 3. 数据查询SQL条件：哪些数据项的列名称经常出现在WHERE、GROUP BY、ORDER BY子句中等；   

> 4. 数据更新类SQL条件：有多少列经常出现UPDATE或DELETE 的WHERE子句中；   

> 5. SQL量的统计比，如：SELECT：UPDATE+DELETE：INSERT=多少？   

> 6. 预计大表及相关联的SQL，每天总的执行量在何数量级？
   
> 7. 表中的数据：更新为主的业务 还是 查询为主的业务   

> 8. 打算采用什么数据库物理服务器，以及数据库服务器架构？   

> 9. 并发如何？   

> 10. 存储引擎选择InnoDB还是MyISAM？   

大致明白以上10个问题，至于如何设计此类的大表，应该什么都清楚了！ 

至于优化若是指创建好的表，不能变动表结构的话，那建议InnoDB引擎，多利用点内存，减轻磁盘IO负载，因为IO往往是数据库服务器的瓶颈 

另外对优化索引结构去解决性能问题的话，建议优先考虑修改类SQL语句，使他们更快些，不得已只靠索引组织结构的方式，当然此话前提是， 
索引已经创建的非常好，若是读为主，可以考虑打开query_cache， 

以及调整一些参数值：sort_buffer_size,read_buffer_size,read_rnd_buffer_size,join_buffer_size 

现在的公司有三张表，是5亿的数据，每天张表每天的增量是100w 
每张表大概在10个columns左右 
下面是我做的测试和对比 

1. 首先看engine,在大数据量情况下，在没有做分区的情况下 
mysiam比innodb在只读的情况下，效率要高13％左右 

2. 在做了partition之后，你可以去读一下mysql的官方文档，其实对于partition，专门是对myisam做的优化，对于innodb，所有的数据是存在ibdata里面的，所以即使你可以看到schema变了，其实没有本质的变化 
在分区出于同一个physical disk下面的情况下，提升大概只有1％ 
在分区在不同的physical disk下，我分到了三个不同的disks下，提升大概在3％，其实所谓的吞吐量，由很多因素决定的，比如你的explain parition时候可以看到，record在那一个分区，如果每个分区都有，其实本质上没有解决读的问题，这样只会提升写的效率。 另外一个问题在于，分区，你怎么分，如果一张表，有三个column都是经常被用于做查询条件的，其实是一件很悲惨的事情，因为你没有办法对所有的sql做针对性的分区，如果你只是如mysql官方文档上说的，只对时间做一个分区，而且你也只用时间查询的话，恭喜你 

3. 表主要用来读还是写，其实这个问题是不充分的，应该这样问，你在写入的时候，同时并发的查询多么？我的问题还比较简单，因为mongodb的shredding支持不能，在crush之后，还是回到mysql，所以在通常情况下，9am－9pm，写入的情况很多，这个时候我会做一个view，view是基于最近被插入或者经常被查询的，通过做view来分离读取，就是说写是在table上的，读在进行逻辑判断前是在view上操作的 

4. 做一些archive table，比如先对这些大表做很多已有的统计分析，然后通过已有的分析＋增量来解决 

5. 如果你用mysiam，还有一个问题你要注意，如果你的.configure的时候，加了一个max index length参数的时候，当你的record数大于制定长度的时候，这个index会被disable 